{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgqB4uy0evQbqGxKXoSXc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iampundir/Spark-Project/blob/master/Spark_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LlbnjV3B7Gr",
        "colab_type": "text"
      },
      "source": [
        "a new user spends 20 seconds on the website and\n",
        "we have to predict if this user will convert or not using the Logistic regression\n",
        "line. We use the regression equation and try to predict the y value for\n",
        "20 seconds time spent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBQ_ImfccunX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d4b80600-0d97-4891-caf7-0c1dedc9337b"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "#!wget -q http://apache.osuosl.org/spark/spark-2.4.0/spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#wget -q http://apache.osuosl.org/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!wget -q http://apache.osuosl.org/spark/spark-2.4.6/spark-2.4.6-bin-hadoop2.7.tgz\n",
        "\n",
        "#!tar xf spark-2.4.0-bin-hadoop2.7.tgz\n",
        "#!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.6-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Wa\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Waiting for headers] [Wa\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rHit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CntGSifcxc8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.0-bin-hadoop2.7\"\n",
        "#os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.6-bin-hadoop2.7\""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdfdX_-_c8Bp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n",
        "import urllib.request"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zaHyG1wq3s9I",
        "colab_type": "text"
      },
      "source": [
        "We then load and read the dataset within Spark using Dataframe. We have\n",
        "to make sure we have opened the PySpark from the same directory folder\n",
        "where the dataset is available or else we have to mention the directory path\n",
        "of the data folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKhXEn3AbCWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.appName('log_reg').getOrCreate()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vStZRiu36t8",
        "colab_type": "text"
      },
      "source": [
        "Now we will upload the required data file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW48UELjecgf",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "a5672728-4456-45f8-f5ee-7ef63a3daf15"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73eaddb0-21ad-4504-8718-fb60f4c44f7c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73eaddb0-21ad-4504-8718-fb60f4c44f7c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Logistic_data.csv to Logistic_data (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpimFBv23-su",
        "colab_type": "text"
      },
      "source": [
        "Lets check the file "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Beg_FJVmetno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "584e7bdd-b1f6-4e54-8954-3199eeaca87e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Logistic_data (1).csv'   spark-2.4.6-bin-hadoop2.7\n",
            " Logistic_data.csv\t  spark-2.4.6-bin-hadoop2.7.tgz\n",
            " sample_data\t\t  spark-2.4.6-bin-hadoop2.7.tgz.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNnsKjte4BqR",
        "colab_type": "text"
      },
      "source": [
        "Now we will load the file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t71x7g6cbCR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#read the dataset\n",
        "df=spark.read.csv(\"Logistic_data.csv\",inferSchema=True,header=True)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eG3LgiagbCQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import *"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk3kCCHD3zk1",
        "colab_type": "text"
      },
      "source": [
        "**Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDug56tIbCMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8f8f40b-c1ce-47d5-a805-1604cebc5d4e"
      },
      "source": [
        "#check the shape of the data \n",
        "print((df.count(),len(df.columns)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ay873RMG4MXC",
        "colab_type": "text"
      },
      "source": [
        "the above output confirms the size of our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn5jHGo34UO-",
        "colab_type": "text"
      },
      "source": [
        "we can then\n",
        "validate the datatypes of the input values to check if we need to change/\n",
        "cast any columns datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOuyee2rbCLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "854aa0fd-72ee-458d-c3c9-87f49be2250e"
      },
      "source": [
        "#printSchema\n",
        "df.printSchema()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Repeat_Visitor: integer (nullable = true)\n",
            " |-- Platform: string (nullable = true)\n",
            " |-- Web_pages_viewed: integer (nullable = true)\n",
            " |-- Status: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rbruduJ4bg-",
        "colab_type": "text"
      },
      "source": [
        "As we can see, there are two such columns (Country, Search_Engine),\n",
        "which are categorical in nature and hence need to be converted into\n",
        "numerical form."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPw6Cr7rbCH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "53d9828a-3478-439d-dfa2-737733071cbf"
      },
      "source": [
        "#number of columns in dataset\n",
        "df.columns"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['_c0',\n",
              " 'Country',\n",
              " 'Age',\n",
              " 'Repeat_Visitor',\n",
              " 'Platform',\n",
              " 'Web_pages_viewed',\n",
              " 'Status']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80zUyBTH5WSB",
        "colab_type": "text"
      },
      "source": [
        "Let’s have a look at the dataset using the show function in\n",
        "Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVjrnGuibCFw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c0b5cd8c-db8e-49fb-c9aa-f9dd9d405a08"
      },
      "source": [
        "#view the dataset\n",
        "df.show(5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---------+---+--------------+--------+----------------+------+\n",
            "|_c0|  Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|\n",
            "+---+---------+---+--------------+--------+----------------+------+\n",
            "|  0|    India| 41|             1|   Yahoo|              21|     1|\n",
            "|  1|   Brazil| 28|             1|   Yahoo|               5|     0|\n",
            "|  2|   Brazil| 40|             0|  Google|               3|     0|\n",
            "|  3|Indonesia| 31|             1|    Bing|              15|     1|\n",
            "|  4| Malaysia| 32|             0|  Google|              15|     1|\n",
            "+---+---------+---+--------------+--------+----------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq83gEQS5aek",
        "colab_type": "text"
      },
      "source": [
        "We can now use the describe function to go over statistical measures of\n",
        "the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGPqg4mgbCB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "de419258-4092-4508-d8ca-c26bba341d12"
      },
      "source": [
        "#Exploratory Data Analysis\n",
        "df.describe().show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
            "|summary|              _c0| Country|              Age|   Repeat_Visitor|Platform| Web_pages_viewed|            Status|\n",
            "+-------+-----------------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
            "|  count|            20000|   20000|            20000|            20000|   20000|            20000|             20000|\n",
            "|   mean|           9999.5|    null|         28.53955|           0.5029|    null|           9.5533|               0.5|\n",
            "| stddev|5773.647027659381|    null|7.888912950773227|0.500004090187782|    null|6.073903499824976|0.5000125004687693|\n",
            "|    min|                0|  Brazil|               17|                0|    Bing|                1|                 0|\n",
            "|    max|            19999|Malaysia|              111|                1|   Yahoo|               29|                 1|\n",
            "+-------+-----------------+--------+-----------------+-----------------+--------+-----------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwyc6gzI5iPV",
        "colab_type": "text"
      },
      "source": [
        "We can observe that the average age of visitors is close to 28 years, and\n",
        "they view around 9 web pages during the website visit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uxLMB8V5wlI",
        "colab_type": "text"
      },
      "source": [
        "Let us explore individual columns to understand the data in deeper\n",
        "details. The groupBy function used along with counts returns the\n",
        "frequency of each of the categories in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPD5zDGb5ix6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fa3c7628-579f-462d-d1a2-9e9c085801d5"
      },
      "source": [
        "df.groupBy('Country').count().show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|  Country|count|\n",
            "+---------+-----+\n",
            "| Malaysia| 1218|\n",
            "|    India| 4018|\n",
            "|Indonesia|12178|\n",
            "|   Brazil| 2586|\n",
            "+---------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRiSL7136Ccb",
        "colab_type": "text"
      },
      "source": [
        "So, the maximum number of visitors are from Indonesia, followed by\n",
        "India"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoE0DHcZbB6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "0bea93f0-9137-4c1e-b8b7-a72bdd30227c"
      },
      "source": [
        "df.groupBy('Platform').count().show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+\n",
            "|Platform|count|\n",
            "+--------+-----+\n",
            "|   Yahoo| 9859|\n",
            "|    Bing| 4360|\n",
            "|  Google| 5781|\n",
            "+--------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N60Ang636IyG",
        "colab_type": "text"
      },
      "source": [
        "The Yahoo search engine users are the highest in numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku-2rurvbBv-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d8ce6994-3a58-422f-cfe8-39a15c1ed5ba"
      },
      "source": [
        "df.groupBy('Status').count().show()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Status|count|\n",
            "+------+-----+\n",
            "|     1|10000|\n",
            "|     0|10000|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdpcV8FA6Obd",
        "colab_type": "text"
      },
      "source": [
        "We have an equal number of users who are converted and nonconverted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKkPEH756UFR",
        "colab_type": "text"
      },
      "source": [
        "Let’s use the groupBy function along with the mean to know more\n",
        "about the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjAmhXbsYc_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "c19c2062-ff2f-47a1-90de-028f8a3f76fc"
      },
      "source": [
        "df.groupBy('Country').mean().show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+------------------+------------------+-------------------+---------------------+--------------------+\n",
            "|  Country|          avg(_c0)|          avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|         avg(Status)|\n",
            "+---------+------------------+------------------+-------------------+---------------------+--------------------+\n",
            "| Malaysia| 9814.097701149425|27.792282430213465| 0.5730706075533661|   11.192118226600986|  0.6568144499178982|\n",
            "|    India| 9998.998506719761|27.976854156296664| 0.5433051269288203|   10.727227476356397|  0.6212045793927327|\n",
            "|Indonesia|10028.314419444901| 28.43159796354081| 0.5207751683363442|    9.985711939563148|  0.5422893742814913|\n",
            "|   Brazil| 9951.910286156226|30.274168600154677|  0.322892498066512|    4.921113689095128|0.038669760247486466|\n",
            "+---------+------------------+------------------+-------------------+---------------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxH-A_w67ABt",
        "colab_type": "text"
      },
      "source": [
        "We have the highest conversion rate from Malaysia, followed by India.\n",
        "The average number of web page visits is highest in Malaysia and lowest in\n",
        "Brazil."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I30hr05I6X51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b6adaeaa-3a0d-4af3-b4ac-0dfdb1122c4c"
      },
      "source": [
        "df.groupBy('Platform').mean().show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+------------------+------------------+-------------------+---------------------+------------------+\n",
            "|Platform|          avg(_c0)|          avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|       avg(Status)|\n",
            "+--------+------------------+------------------+-------------------+---------------------+------------------+\n",
            "|   Yahoo|10029.549548635765|28.569226087838523| 0.5094837204584644|    9.599655137437875|0.5071508266558474|\n",
            "|    Bing|10086.784403669724| 28.68394495412844| 0.4720183486238532|    9.114908256880733|0.4559633027522936|\n",
            "|  Google| 9882.423629129908|28.380038055699707| 0.5149628092025601|    9.804878048780488|0.5210171250648676|\n",
            "+--------+------------------+------------------+-------------------+---------------------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcjbNcTT7Mim",
        "colab_type": "text"
      },
      "source": [
        "We have the highest conversion rate from user visitors use the Google\n",
        "search engine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV3jABHp7EyT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "ef89b7b6-e7d7-42c6-ae23-cb977d17cbdc"
      },
      "source": [
        "df.groupBy('Status').mean().show()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+---------+--------+-------------------+---------------------+-----------+\n",
            "|Status| avg(_c0)|avg(Age)|avg(Repeat_Visitor)|avg(Web_pages_viewed)|avg(Status)|\n",
            "+------+---------+--------+-------------------+---------------------+-----------+\n",
            "|     1|10007.333| 26.5435|             0.7019|              14.5617|        1.0|\n",
            "|     0| 9991.667| 30.5356|             0.3039|               4.5449|        0.0|\n",
            "+------+---------+--------+-------------------+---------------------+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgb3vbK07WJY",
        "colab_type": "text"
      },
      "source": [
        "We can clearly see there is a strong connection between the conversion\n",
        "status and the number of pages viewed along with repeat visits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfNVCySQ95Vf",
        "colab_type": "text"
      },
      "source": [
        "**Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9BxHc9D2PnA",
        "colab_type": "text"
      },
      "source": [
        "This is the part where we convert the categorical variable into numerical\n",
        "form and create a single vector combining all the input features by using\n",
        "Spark’s VectorAssembler."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a50AbcLt7Tli",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import required libraries\n",
        "\n",
        "from pyspark.ml.feature import StringIndexer"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbNes4fs25UA",
        "colab_type": "text"
      },
      "source": [
        "Since we are dealing with two categorical columns, we will have to\n",
        "convert the country and search engine columns into numerical form. The\n",
        "machine learning model cannot understand categorical values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIlv3twb2-L2",
        "colab_type": "text"
      },
      "source": [
        "The first step is to label the column using StringIndexer into\n",
        "numerical form. It allocates unique values to each of the categories of the\n",
        "column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkzPZrFj2TJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "search_engine_indexer = StringIndexer(inputCol=\"Platform\", outputCol=\"Search_Engine_Num\").fit(df)\n",
        "df = search_engine_indexer.transform(df)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTSux-g13iQz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "16512df9-672e-40d0-d0ec-5646a788e782"
      },
      "source": [
        "df.show(3,False)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------+---+--------------+--------+----------------+------+-----------------+\n",
            "|_c0|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Search_Engine_Num|\n",
            "+---+-------+---+--------------+--------+----------------+------+-----------------+\n",
            "|0  |India  |41 |1             |Yahoo   |21              |1     |0.0              |\n",
            "|1  |Brazil |28 |1             |Yahoo   |5               |0     |0.0              |\n",
            "|2  |Brazil |40 |0             |Google  |3               |0     |1.0              |\n",
            "+---+-------+---+--------------+--------+----------------+------+-----------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ev1BMnws3h4N",
        "colab_type": "text"
      },
      "source": [
        "The next step is to represent each of these values into the form of a\n",
        "one hot encoded vector. However, this vector is a little different in terms of\n",
        "representation as it captures the values and position of the values in the vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2LQIgRv3Dr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encoding\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "search_engine_encoder = OneHotEncoder(inputCol=\"Search_Engine_Num\", outputCol=\"Search_Engine_Vector\")\n",
        "df = search_engine_encoder.transform(df)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1okxziFg3uxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "4bb73793-bc99-42b5-aebc-cc96339b13d6"
      },
      "source": [
        "df.show(3,False)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+-------+---+--------------+--------+----------------+------+-----------------+--------------------+\n",
            "|_c0|Country|Age|Repeat_Visitor|Platform|Web_pages_viewed|Status|Search_Engine_Num|Search_Engine_Vector|\n",
            "+---+-------+---+--------------+--------+----------------+------+-----------------+--------------------+\n",
            "|0  |India  |41 |1             |Yahoo   |21              |1     |0.0              |(2,[0],[1.0])       |\n",
            "|1  |Brazil |28 |1             |Yahoo   |5               |0     |0.0              |(2,[0],[1.0])       |\n",
            "|2  |Brazil |40 |0             |Google  |3               |0     |1.0              |(2,[1],[1.0])       |\n",
            "+---+-------+---+--------------+--------+----------------+------+-----------------+--------------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXiHlRGZ34gN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "5258f9b2-29e3-47cb-ca21-ab305856cc8d"
      },
      "source": [
        "df.groupBy('Platform').count().orderBy('count',ascending=False).show(5,False)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-----+\n",
            "|Platform|count|\n",
            "+--------+-----+\n",
            "|Yahoo   |9859 |\n",
            "|Google  |5781 |\n",
            "|Bing    |4360 |\n",
            "+--------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPaLx7DK38fv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b86b0cab-9198-4358-8ebf-5df96433683a"
      },
      "source": [
        "df.groupBy('Search_Engine_Num').count().orderBy('count',ascending=False).show(5,False)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------+-----+\n",
            "|Search_Engine_Num|count|\n",
            "+-----------------+-----+\n",
            "|0.0              |9859 |\n",
            "|1.0              |5781 |\n",
            "|2.0              |4360 |\n",
            "+-----------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubz0ejlY4UdA",
        "colab_type": "text"
      },
      "source": [
        "The final feature that we would be using for building Logistic\n",
        "Regression is Search_Engine_Vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7UTfzl44Hfs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "05878876-981c-476a-9f67-bfbcee5f7173"
      },
      "source": [
        "df.groupBy('Search_Engine_Vector').count().orderBy('count',ascending=False).show(5,False)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|Search_Engine_Vector|count|\n",
            "+--------------------+-----+\n",
            "|(2,[0],[1.0])       |9859 |\n",
            "|(2,[1],[1.0])       |5781 |\n",
            "|(2,[],[])           |4360 |\n",
            "+--------------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACxUiEce4au4",
        "colab_type": "text"
      },
      "source": [
        " Let’s understand what these column\n",
        "values represent.\n",
        "\n",
        " (2,[0],[1.0]) represents a vector of length 2 , with 1 value :\n",
        "\n",
        "Size of Vector – 2\n",
        "\n",
        "Value contained in vector – 1.0\n",
        "\n",
        "Position of 1.0 value in vector – 0th place"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zxk71LAA4neU",
        "colab_type": "text"
      },
      "source": [
        "This kind of representation allows the saving of computational space\n",
        "and hence a faster time to compute. The length of the vector is equal to\n",
        "one less than the total number of elements since each value can be easily\n",
        "represented with just the help of two columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtwyot874u2-",
        "colab_type": "text"
      },
      "source": [
        "Let’s repeat the same procedure for the other categorical column\n",
        "(Country)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXisyUjH4LEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country_indexer = StringIndexer(inputCol=\"Country\", outputCol=\"Country_Num\").fit(df)\n",
        "df = country_indexer.transform(df)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwTgniO14yW6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7d7c8832-3cab-466c-8565-8bff71308c1e"
      },
      "source": [
        "df.select(['Country','Country_Num']).show(3,False)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+\n",
            "|Country|Country_Num|\n",
            "+-------+-----------+\n",
            "|India  |1.0        |\n",
            "|Brazil |2.0        |\n",
            "|Brazil |2.0        |\n",
            "+-------+-----------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwtHXnAh48Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#one hot encoding\n",
        "country_encoder = OneHotEncoder(inputCol=\"Country_Num\", outputCol=\"Country_Vector\")\n",
        "df = country_encoder.transform(df)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOW4Rt7C41Zj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "8a15ff51-5795-41db-a115-6b44faceb2f4"
      },
      "source": [
        "df.select(['Country','country_Num','Country_Vector']).show(3,False)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-----------+--------------+\n",
            "|Country|country_Num|Country_Vector|\n",
            "+-------+-----------+--------------+\n",
            "|India  |1.0        |(3,[1],[1.0]) |\n",
            "|Brazil |2.0        |(3,[2],[1.0]) |\n",
            "|Brazil |2.0        |(3,[2],[1.0]) |\n",
            "+-------+-----------+--------------+\n",
            "only showing top 3 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNajmRQk5Ap1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "fcedc342-dffa-4fc4-8214-08350086612f"
      },
      "source": [
        "df.groupBy('Country').count().orderBy('count',ascending=False).show(5,False)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|Country  |count|\n",
            "+---------+-----+\n",
            "|Indonesia|12178|\n",
            "|India    |4018 |\n",
            "|Brazil   |2586 |\n",
            "|Malaysia |1218 |\n",
            "+---------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIDwdNwo5DP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "9078c03d-112f-4a9a-e3e8-e1e1c1de7589"
      },
      "source": [
        "df.groupBy('Country_Num').count().orderBy('count',ascending=False).show(5,False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+-----+\n",
            "|Country_Num|count|\n",
            "+-----------+-----+\n",
            "|0.0        |12178|\n",
            "|1.0        |4018 |\n",
            "|2.0        |2586 |\n",
            "|3.0        |1218 |\n",
            "+-----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBW_STzH5F0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "57bfc037-8167-4462-c1fb-e495a212d572"
      },
      "source": [
        "df.groupBy('Country_Vector').count().orderBy('count',ascending=False).show(5,False)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+-----+\n",
            "|Country_Vector|count|\n",
            "+--------------+-----+\n",
            "|(3,[0],[1.0]) |12178|\n",
            "|(3,[1],[1.0]) |4018 |\n",
            "|(3,[2],[1.0]) |2586 |\n",
            "|(3,[],[])     |1218 |\n",
            "+--------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HG7pMTZW5QAR",
        "colab_type": "text"
      },
      "source": [
        "Now that we have converted both the categorical columns into\n",
        "numerical forms, we need to assemble all of the input columns into a\n",
        "single vector that would act as the input feature for the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLCH5E2b5Tv3",
        "colab_type": "text"
      },
      "source": [
        "So, we select the input columns that we need to use to create the single\n",
        "feature vector and name the output vector as features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrnjZS9q5LDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTzLFi2-5XLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_assembler = VectorAssembler(inputCols=['Search_Engine_Vector','Country_Vector','Age', 'Repeat_Visitor','Web_pages_viewed'], outputCol=\"features\")\n",
        "df = df_assembler.transform(df)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7iKlIRE57SP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2e4bec45-e456-443a-9130-6f5ac87e75b3"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: integer (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Repeat_Visitor: integer (nullable = true)\n",
            " |-- Platform: string (nullable = true)\n",
            " |-- Web_pages_viewed: integer (nullable = true)\n",
            " |-- Status: integer (nullable = true)\n",
            " |-- Search_Engine_Num: double (nullable = false)\n",
            " |-- Search_Engine_Vector: vector (nullable = true)\n",
            " |-- Country_Num: double (nullable = false)\n",
            " |-- Country_Vector: vector (nullable = true)\n",
            " |-- features: vector (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j30fVHxq5Kme",
        "colab_type": "text"
      },
      "source": [
        "As we can see, now we have one extra column named features, which\n",
        "is nothing but a combination of all the input features represented as a\n",
        "single dense vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9s4egrn5_qs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "d7abeb80-cf2d-4258-e874-24170dfe8034"
      },
      "source": [
        "df.select(['features','Status']).show(10,False)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------------+------+\n",
            "|features                           |Status|\n",
            "+-----------------------------------+------+\n",
            "|[1.0,0.0,0.0,1.0,0.0,41.0,1.0,21.0]|1     |\n",
            "|[1.0,0.0,0.0,0.0,1.0,28.0,1.0,5.0] |0     |\n",
            "|(8,[1,4,5,7],[1.0,1.0,40.0,3.0])   |0     |\n",
            "|(8,[2,5,6,7],[1.0,31.0,1.0,15.0])  |1     |\n",
            "|(8,[1,5,7],[1.0,32.0,15.0])        |1     |\n",
            "|(8,[1,4,5,7],[1.0,1.0,32.0,3.0])   |0     |\n",
            "|(8,[1,4,5,7],[1.0,1.0,32.0,6.0])   |0     |\n",
            "|(8,[1,2,5,7],[1.0,1.0,27.0,9.0])   |0     |\n",
            "|(8,[0,2,5,7],[1.0,1.0,32.0,2.0])   |0     |\n",
            "|(8,[2,5,6,7],[1.0,31.0,1.0,16.0])  |1     |\n",
            "+-----------------------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4yd-EQd6G8C",
        "colab_type": "text"
      },
      "source": [
        "Let us select only features column as input and the Status column as\n",
        "output for training the logistic regression model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFdfeTXj5IXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#select data for building model\n",
        "model_df=df.select(['features','Status'])"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwEGf8R26NIx",
        "colab_type": "text"
      },
      "source": [
        "**Splitting the Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9s29jTe6UvL",
        "colab_type": "text"
      },
      "source": [
        "We have to split the dataset into a training and test dataset in order to train\n",
        "and evaluate the performance of the logistic regression model. We split it\n",
        "in a 75/25 ratio and train our model on 75% of the dataset. Another use of\n",
        "splitting the data is that we can use 75% of the data to apply cross-validation\n",
        "in order to come up with the best Hyperparameters. Cross-validation can be\n",
        "of a different type where one part of the training data is kept for training and\n",
        "the remaining part is used for validation purposes. K-fold cross-validation is\n",
        "primarily used to train the model with the best Hyperparameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWY6QI4A6YAU",
        "colab_type": "text"
      },
      "source": [
        "We can print the shape of train and test data to validate the size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj2ETsnD6KYX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RohXd-zz6a4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the data \n",
        "training_df,test_df=model_df.randomSplit([0.75,0.25])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGVWzNop6em-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cada814e-1ffc-4563-e8b8-905510393abd"
      },
      "source": [
        "training_df.count()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlXs2PnV6gYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dbc55460-9eab-45f0-ea4f-9348ace29598"
      },
      "source": [
        "training_df.groupBy('Status').count().show()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Status|count|\n",
            "+------+-----+\n",
            "|     1| 7476|\n",
            "|     0| 7518|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC6-3xng6i4J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d586952f-5942-49b7-9426-2f6ff362bdf7"
      },
      "source": [
        "test_df.count()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ufu6ZUv6oFG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "66a549ee-86b1-4307-e15f-66b54932fe13"
      },
      "source": [
        "test_df.groupBy('Status').count().show()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|Status|count|\n",
            "+------+-----+\n",
            "|     1| 2524|\n",
            "|     0| 2482|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL5Ztqa_6vfQ",
        "colab_type": "text"
      },
      "source": [
        "**Build and Train Logistic Regression Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zgzp2B664Lq",
        "colab_type": "text"
      },
      "source": [
        "Now,we build and train the logistic regression model using features\n",
        "as the input column and status as the output column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBe0PLww6qCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from pyspark.ml.classification import LogisticRegression"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACpPkXjz602X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_reg=LogisticRegression(labelCol='Status').fit(training_df)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp9IExIz7KEG",
        "colab_type": "text"
      },
      "source": [
        "**Training Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_72ay2TM7N2w",
        "colab_type": "text"
      },
      "source": [
        "We can access the predictions made by the model using the evaluate\n",
        "function in Spark that executes all the steps in an optimized way. That\n",
        "gives another Dataframe that contains four columns in total, including\n",
        "prediction and probability. The prediction column signifies the class\n",
        "label that the model has predicted for the given row and probability\n",
        "column contains two probabilities (probability for negative class at 0th\n",
        "index and probability for positive class at 1st index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1naNVfZW69Fc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "3153711c-d9cb-4cb5-ef1a-60ad02184c9a"
      },
      "source": [
        "#Training Results\n",
        "train_results=log_reg.evaluate(training_df).predictions\n",
        "train_results.filter(train_results['Status']==1).filter(train_results['prediction']==1).select(['Status','prediction','probability']).show(10,False)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----------+----------------------------------------+\n",
            "|Status|prediction|probability                             |\n",
            "+------+----------+----------------------------------------+\n",
            "|1     |1.0       |[0.3075148055014183,0.6924851944985817] |\n",
            "|1     |1.0       |[0.3075148055014183,0.6924851944985817] |\n",
            "|1     |1.0       |[0.3075148055014183,0.6924851944985817] |\n",
            "|1     |1.0       |[0.1717327850840228,0.8282672149159772] |\n",
            "|1     |1.0       |[0.1717327850840228,0.8282672149159772] |\n",
            "|1     |1.0       |[0.1717327850840228,0.8282672149159772] |\n",
            "|1     |1.0       |[0.1717327850840228,0.8282672149159772] |\n",
            "|1     |1.0       |[0.08826315592210453,0.9117368440778955]|\n",
            "|1     |1.0       |[0.08826315592210453,0.9117368440778955]|\n",
            "|1     |1.0       |[0.08826315592210453,0.9117368440778955]|\n",
            "+------+----------+----------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13C5NZd-7GTy",
        "colab_type": "text"
      },
      "source": [
        "Probability at 0 index is for 0 class and probabilty as 1 index is for 1 class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sTj8hNK7R75",
        "colab_type": "text"
      },
      "source": [
        "So, in the above results, probability at the 0th index is for Status = 0\n",
        "and probability as 1st index is for Status =1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0CdIN927ECb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct_preds=train_results.filter(train_results['Status']==1).filter(train_results['prediction']==1).count()"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdvsZoLY88uB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4cfeefca-8d4a-4abc-ef89-2cda4be86af0"
      },
      "source": [
        "\n",
        "training_df.filter(training_df['Status']==1).count()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7476"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsioStu28-U3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c405181e-8562-4540-9de3-337de83cda56"
      },
      "source": [
        "#accuracy on training dataset \n",
        "float(correct_preds)/(training_df.filter(training_df['Status']==1).count())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9394060995184591"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e76rKLk9IW-",
        "colab_type": "text"
      },
      "source": [
        "We can filter the columns that we want to see using the select keyword."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvijc4EH9AOm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b5685389-a235-4764-c70f-ec1c938f7f9c"
      },
      "source": [
        "#Test Set results\n",
        "results=log_reg.evaluate(test_df).predictions\n",
        "results.select(['Status','prediction']).show(10,False)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+----------+\n",
            "|Status|prediction|\n",
            "+------+----------+\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|0     |0.0       |\n",
            "|1     |0.0       |\n",
            "|0     |0.0       |\n",
            "+------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF0y_GFf9Fs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a0b6aca0-850d-4ea8-bfde-43ebdf186fe9"
      },
      "source": [
        "results.printSchema()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- features: vector (nullable = true)\n",
            " |-- Status: integer (nullable = true)\n",
            " |-- rawPrediction: vector (nullable = true)\n",
            " |-- probability: vector (nullable = true)\n",
            " |-- prediction: double (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJktQSci9b-P",
        "colab_type": "text"
      },
      "source": [
        "Since this is a classification problem, we will use a confusion matrix to\n",
        "gauge the performance of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6NUTcO69elW",
        "colab_type": "text"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSWSNR9M9ieC",
        "colab_type": "text"
      },
      "source": [
        "We will manually create the variables for true positives, true negatives,\n",
        "false positives, and false negatives to understand them better rather than\n",
        "using the direct inbuilt function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfYzN5ll9K9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#confusion matrix\n",
        "true_postives = results[(results.Status == 1) & (results.prediction == 1)].count()\n",
        "true_negatives = results[(results.Status == 0) & (results.prediction == 0)].count()\n",
        "false_positives = results[(results.Status == 0) & (results.prediction == 1)].count()\n",
        "false_negatives = results[(results.Status == 1) & (results.prediction == 0)].count()"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a93QFgVi9m8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "17b67eec-75db-4327-babf-2b3754a6d1f2"
      },
      "source": [
        "print (true_postives)\n",
        "print (true_negatives)\n",
        "print (false_positives)\n",
        "print (false_negatives)\n",
        "print(true_postives+true_negatives+false_positives+false_negatives)\n",
        "print (results.count())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2349\n",
            "2338\n",
            "144\n",
            "175\n",
            "5006\n",
            "5006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuhJ3udy9u4o",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HmhDIj09wcB",
        "colab_type": "text"
      },
      "source": [
        "accuracy is the most basic metric\n",
        "for evaluating any classifier; however, this is not the right indicator of\n",
        "the performance of the model due to dependency on the target class\n",
        "balance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZSqbcWf-FSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b33d576-b6f3-4fc2-9015-177679c1126a"
      },
      "source": [
        "accuracy=float((true_postives+true_negatives) /(results.count()))\n",
        "print(accuracy)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9362764682381143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpLaPdC497Zs",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of the model that we have built is around 94%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W507ekN-6Ds",
        "colab_type": "text"
      },
      "source": [
        "**Recall**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9eofWGs-89y",
        "colab_type": "text"
      },
      "source": [
        "Recall rate shows how much of the positive class cases we are able to\n",
        "predict correctly out of the total positive class observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb4XWbdn9pW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4655edb9-1351-45e0-f161-81e588db4cc5"
      },
      "source": [
        "recall = float(true_postives)/(true_postives + false_negatives)\n",
        "print(recall)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9306656101426307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pboFSC3W_0XY",
        "colab_type": "text"
      },
      "source": [
        "The recall rate of the model is around 93%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07VAfqAh__xE",
        "colab_type": "text"
      },
      "source": [
        "Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0Fz0rHYAFdh",
        "colab_type": "text"
      },
      "source": [
        "Precision rate talks about the number of true positives predicted\n",
        "correctly out of all the predicted positives observations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GuMDo7B9rjN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d3fa7f9-3f30-45c7-ed78-57e5976bc33a"
      },
      "source": [
        "precision = float(true_postives) / (true_postives + false_positives)\n",
        "print(precision)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9422382671480144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU4_wUd_AKNl",
        "colab_type": "text"
      },
      "source": [
        "So, the recall rate and precision rate are also in the same range, which\n",
        "is due to the fact that our target class was well balanced."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0a8Xs8dADHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}